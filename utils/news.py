"""
æ–°é—»è·å–å™¨ - å¸¦ AI ä¸­æ–‡æ‘˜è¦
- è·å– HackerNews çƒ­é—¨æ–°é—»
- ç”¨ Gemini Flash ç”Ÿæˆä¸­æ–‡æ‘˜è¦
- æ–‡ä»¶ç¼“å­˜ (10åˆ†é’Ÿæœ‰æ•ˆï¼Œé¿å…é¢‘ç¹è°ƒç”¨)
"""
import urllib.request
import json
import time
from pathlib import Path

# ç¼“å­˜é…ç½®
CACHE_DIR = Path(__file__).parent.parent / "data"
CACHE_FILE = CACHE_DIR / "news_cache.json"
CACHE_TTL = 10 * 60  # 10åˆ†é’Ÿ


class NewsFetcher:
    def __init__(self, cache_ttl=600):
        self.cache_ttl = cache_ttl
        self._current_index = 0
        CACHE_DIR.mkdir(parents=True, exist_ok=True)
    
    def _load_cache(self):
        """åŠ è½½æ–‡ä»¶ç¼“å­˜"""
        if not CACHE_FILE.exists():
            return None
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
            if time.time() - data.get('timestamp', 0) > CACHE_TTL:
                return None
            return data.get('news', [])
        except:
            return None
    
    def _save_cache(self, news_list):
        """ä¿å­˜æ–‡ä»¶ç¼“å­˜"""
        try:
            with open(CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump({
                    'timestamp': time.time(),
                    'news': news_list
                }, f, ensure_ascii=False)
        except:
            pass
    
    def _fetch_hn_stories(self, limit=3):
        """è·å– HackerNews åŸå§‹æ–°é—»"""
        try:
            url = "https://hacker-news.firebaseio.com/v0/topstories.json"
            req = urllib.request.Request(url, headers={'User-Agent': 'Python-CLI'})
            with urllib.request.urlopen(req, timeout=5) as response:
                ids = json.loads(response.read().decode())[:limit]
            
            stories = []
            for item_id in ids:
                item_url = f"https://hacker-news.firebaseio.com/v0/item/{item_id}.json"
                with urllib.request.urlopen(item_url, timeout=3) as resp:
                    item = json.loads(resp.read().decode())
                    stories.append({
                        "title": item.get('title', 'Unknown'),
                        "url": item.get('url', ''),
                        "score": item.get('score', 0),
                        "summary": ""  # å¾… AI å¡«å……
                    })
            return stories
        except Exception:
            return []
    
    def _generate_summaries(self, stories):
        """ç”¨ Gemini Flash ç”Ÿæˆä¸­æ–‡æ‘˜è¦"""
        try:
            from core.client import get_client
            client = get_client()
            
            # æ‰¹é‡ç­›é€‰+ç”Ÿæˆç®€ä»‹ (ä¸€æ¬¡è¯·æ±‚)
            titles = [f"{i+1}. {s['title']}" for i, s in enumerate(stories)]
            prompt = (
                "ä½ æ˜¯ç§‘æŠ€æ–°é—»ç¼–è¾‘ã€‚ä»ä»¥ä¸‹ Hacker News æ ‡é¢˜ä¸­ï¼Œé€‰å‡ºæœ€ç¬¦åˆã€AI/å¤§æ¨¡å‹/æ¸¸æˆ/æå®¢/ç¼–ç¨‹ã€‘é¢†åŸŸçš„3æ¡ã€‚\n"
                "å¯¹æ¯æ¡ç”¨ä¸­æ–‡å†™ä¸€å¥è¯ç®€ä»‹ï¼ˆ50å­—å†…ï¼‰ï¼Œè®©è¯»è€…ç†è§£æ ¸å¿ƒå†…å®¹ã€‚\n"
                "æ ¼å¼ï¼šåºå·|ä¸­æ–‡ç®€ä»‹ï¼ˆåªè¿”å›3è¡Œï¼Œä¸è¦å…¶ä»–å†…å®¹ï¼‰\n\n"
                + "\n".join(titles)
            )
            
            response = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=prompt
            )
            
            # è§£æç»“æœ (æ ¼å¼: "åºå·|ä¸­æ–‡ç®€ä»‹")
            lines = response.text.strip().split('\n')
            filtered_stories = []
            for line in lines[:3]:  # æœ€å¤šå–3æ¡
                line = line.strip()
                if '|' in line:
                    parts = line.split('|', 1)
                    try:
                        idx = int(parts[0].strip().rstrip('.')) - 1
                        summary = parts[1].strip()
                        if 0 <= idx < len(stories):
                            story = stories[idx].copy()
                            story['summary'] = summary
                            filtered_stories.append(story)
                    except (ValueError, IndexError):
                        pass
            
            # å¦‚æœç­›é€‰å¤±è´¥ï¼Œè¿”å›åŸå§‹å‰3æ¡
            if filtered_stories:
                return filtered_stories
            else:
                for story in stories[:3]:
                    story['summary'] = story['title']
                return stories[:3]
                    
        except Exception:
            # AI å¤±è´¥æ—¶ä¿ç•™åŸæ ‡é¢˜
            for story in stories[:3]:
                story['summary'] = story['title']
            return stories[:3]
    
    def get_top_stories(self, limit=3):
        """è·å–æ–°é—» (ä¼˜å…ˆä½¿ç”¨ç¼“å­˜)"""
        # 1. å°è¯•è¯»å–ç¼“å­˜
        cached = self._load_cache()
        if cached:
            return cached
        
        # 2. è·å–æ›´å¤šæ–°é—»ä¾› AI ç­›é€‰ (è·å–10æ¡ï¼Œç­›é€‰å‡º3æ¡)
        stories = self._fetch_hn_stories(limit=10)
        if not stories:
            return []
        
        # 3. AI ç”Ÿæˆä¸­æ–‡æ‘˜è¦
        stories = self._generate_summaries(stories)
        
        # 4. ä¿å­˜ç¼“å­˜
        self._save_cache(stories)
        
        return stories
    
    def get_ticker(self):
        """è·å–ä¸€æ¡è½®æ’­æ–°é—»"""
        stories = self.get_top_stories(limit=3)
        if not stories:
            return "ğŸ“° æš‚æ— æœ€æ–°èµ„è®¯"
        
        story = stories[self._current_index % len(stories)]
        self._current_index += 1
        
        # ä¼˜å…ˆæ˜¾ç¤ºä¸­æ–‡æ‘˜è¦
        display = story.get('summary') or story['title']
        return f"[bright_cyan]{display}[/] [yellow](ğŸ”¥{story['score']})[/]"


# å…¨å±€å•ä¾‹
news_fetcher = NewsFetcher()
