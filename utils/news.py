"""
æ–°é—»è·å–å™¨ - Google News RSS + AI ç¿»è¯‘
- ä½¿ç”¨ Google News RSS (å…è´¹æ— éœ€ Key)
- Gemini æ‰¹é‡ç¿»è¯‘ (çœæµ)
- æœ¬åœ°ç¼“å­˜ (30åˆ†é’Ÿæœ‰æ•ˆ)
- æ”¯æŒæ»šåŠ¨æ•ˆæœ
"""
import urllib.request
import json
import time
import re
from pathlib import Path
from html import unescape

# ç¼“å­˜é…ç½®
CACHE_DIR = Path(__file__).parent.parent / "data"
CACHE_FILE = CACHE_DIR / "news_cache.json"
CACHE_TTL = 30 * 60  # 30åˆ†é’Ÿ

# Google News RSS (ä¸­å›½ç§‘æŠ€æ–°é—»)
GOOGLE_NEWS_RSS = "https://news.google.com/rss/topics/CAAqJggKIiBDQkFTRWdvSUwyMHZNRGRqTVhZU0FtVnVHZ0pWVXlnQVAB?hl=en-US&gl=US&ceid=US:en"


class NewsFetcher:
    """æ–°é—»è·å–å™¨ (Google News + AI ç¿»è¯‘)"""
    
    def __init__(self):
        self._news_list = []
        self._current_index = 0
        self._scroll_offset = 0
        CACHE_DIR.mkdir(parents=True, exist_ok=True)
    
    def _load_cache(self) -> list | None:
        """åŠ è½½ç¼“å­˜"""
        if not CACHE_FILE.exists():
            return None
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
            if time.time() - data.get('timestamp', 0) > CACHE_TTL:
                return None
            return data.get('news', [])
        except (json.JSONDecodeError, OSError, KeyError) as e:
            return None
    
    def _save_cache(self, news_list: list):
        """ä¿å­˜ç¼“å­˜"""
        try:
            with open(CACHE_FILE, 'w', encoding='utf-8') as f:
                json.dump({
                    'timestamp': time.time(),
                    'news': news_list
                }, f, ensure_ascii=False)
        except (OSError, IOError) as e:
            pass  # ç¼“å­˜ä¿å­˜å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
    
    def _fetch_google_news(self, limit: int = 10) -> list:
        """ä» Google News RSS è·å–æ–°é—»"""
        try:
            import feedparser
        except ImportError:
            # å¦‚æœæ²¡æœ‰ feedparserï¼Œä½¿ç”¨ç®€å•è§£æ
            return self._fetch_google_news_simple(limit)
        
        try:
            feed = feedparser.parse(GOOGLE_NEWS_RSS)
            stories = []
            for entry in feed.entries[:limit]:
                title = unescape(entry.title)
                # ç§»é™¤æ¥æºæ ‡è¯† (å¦‚ " - TechCrunch")
                title = re.sub(r'\s*-\s*[^-]+$', '', title)
                stories.append({
                    'title': title,
                    'source': entry.get('source', {}).get('title', 'Google News'),
                    'link': entry.link,
                    'summary': '',  # å¾…ç¿»è¯‘
                })
            return stories
        except Exception:
            return []
    
    def _fetch_google_news_simple(self, limit: int = 10) -> list:
        """ç®€å• RSS è§£æ (æ—  feedparser æ—¶)"""
        try:
            req = urllib.request.Request(
                GOOGLE_NEWS_RSS,
                headers={'User-Agent': 'Mozilla/5.0'}
            )
            with urllib.request.urlopen(req, timeout=10) as resp:
                content = resp.read().decode('utf-8')
            
            # ç®€å•æ­£åˆ™æå–
            items = re.findall(r'<item>.*?<title>(.*?)</title>.*?<link>(.*?)</link>.*?</item>', content, re.DOTALL)
            stories = []
            for title, link in items[:limit]:
                title = unescape(re.sub(r'<!\[CDATA\[(.*?)\]\]>', r'\1', title))
                title = re.sub(r'\s*-\s*[^-]+$', '', title)
                stories.append({
                    'title': title,
                    'source': 'Google News',
                    'link': link,
                    'summary': '',
                })
            return stories
        except (urllib.error.URLError, ValueError) as e:
            return []
    
    def _translate_batch(self, stories: list) -> list:
        """æ‰¹é‡ç¿»è¯‘æ–°é—»æ ‡é¢˜ (çœæµ: ä¸€æ¬¡ API è°ƒç”¨)"""
        if not stories:
            return stories
        
        try:
            from core.client import get_client
            client = get_client()
            
            # æ„å»ºæ‰¹é‡ç¿»è¯‘è¯·æ±‚
            titles = [f"{i+1}. {s['title']}" for i, s in enumerate(stories)]
            prompt = (
                "å°†ä»¥ä¸‹è‹±æ–‡ç§‘æŠ€æ–°é—»æ ‡é¢˜ç¿»è¯‘æˆç®€æ´çš„ä¸­æ–‡ï¼ˆæ¯æ¡ä¸è¶…è¿‡50å­—ï¼‰ã€‚\n"
                "æ ¼å¼ï¼šåºå·|ä¸­æ–‡ç¿»è¯‘\n"
                "åªè¿”å›ç¿»è¯‘ç»“æœï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚\n\n"
                + "\n".join(titles)
            )
            
            response = client.models.generate_content(
                model="gemini-2.5-flash",
                contents=prompt
            )
            
            # è§£æç»“æœ
            lines = response.text.strip().split('\n')
            for line in lines:
                if '|' in line:
                    parts = line.split('|', 1)
                    try:
                        idx = int(parts[0].strip().rstrip('.')) - 1
                        translation = parts[1].strip()[:50]
                        if 0 <= idx < len(stories):
                            stories[idx]['summary'] = translation
                    except (ValueError, IndexError):
                        pass  # è§£æå¤±è´¥æ—¶è·³è¿‡æ­¤æ¡
            
            # æœªç¿»è¯‘çš„ä¿ç•™åŸæ ‡é¢˜
            for s in stories:
                if not s['summary']:
                    s['summary'] = s['title'][:50]
            
            return stories
            
        except Exception:
            # ç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸæ ‡é¢˜
            for s in stories:
                s['summary'] = s['title'][:50]
            return stories
    
    def get_top_stories(self, limit: int = 5) -> list:
        """è·å–æ–°é—» (ä¼˜å…ˆä½¿ç”¨ç¼“å­˜)"""
        # 1. å°è¯•ç¼“å­˜
        cached = self._load_cache()
        if cached:
            self._news_list = cached
            return cached
        
        # 2. æŠ“å–æ–°é—»
        stories = self._fetch_google_news(limit=limit * 2)  # å¤šæŠ“ä¸€äº›
        if not stories:
            return []
        
        # 3. æ‰¹é‡ç¿»è¯‘ (çœæµ)
        stories = self._translate_batch(stories[:limit])
        
        # 4. ä¿å­˜ç¼“å­˜
        self._save_cache(stories)
        self._news_list = stories
        
        return stories
    
    def get_ticker(self) -> str:
        """è·å–ä¸€æ¡è½®æ’­æ–°é—»"""
        if not self._news_list:
            self.get_top_stories()
        
        if not self._news_list:
            return "ğŸ“° æš‚æ— æœ€æ–°èµ„è®¯"
        
        story = self._news_list[self._current_index % len(self._news_list)]
        self._current_index += 1
        
        # ä¼˜å…ˆæ˜¾ç¤ºç¿»è¯‘
        display = story.get('summary') or story['title'][:50]
        source = story.get('source', '')[:10]
        return f"ğŸ“° {display} [{source}]"
    
    def _display_width(self, text: str) -> int:
        """è®¡ç®—å­—ç¬¦ä¸²çš„æ˜¾ç¤ºå®½åº¦ï¼ˆä¸­æ–‡ç®—2ï¼Œè‹±æ–‡ç®—1ï¼‰"""
        width = 0
        for char in text:
            # ä¸­æ—¥éŸ©å­—ç¬¦å 2æ ¼
            if '\u4e00' <= char <= '\u9fff' or \
               '\u3400' <= char <= '\u4dbf' or \
               '\uf900' <= char <= '\ufaff' or \
               '\U00020000' <= char <= '\U0002a6df':
                width += 2
            else:
                width += 1
        return width
    
    def _truncate_to_width(self, text: str, max_width: int) -> str:
        """æŒ‰æ˜¾ç¤ºå®½åº¦æˆªæ–­å­—ç¬¦ä¸²"""
        result = []
        current_width = 0
        for char in text:
            char_width = 2 if ('\u4e00' <= char <= '\u9fff' or 
                              '\u3400' <= char <= '\u4dbf' or
                              '\uf900' <= char <= '\ufaff') else 1
            if current_width + char_width > max_width:
                break
            result.append(char)
            current_width += char_width
        # ç”¨ç©ºæ ¼å¡«å……åˆ°ç²¾ç¡®å®½åº¦
        while current_width < max_width:
            result.append(' ')
            current_width += 1
        return ''.join(result)

    def get_scrolling_text(self, width: int = 60) -> str:
        """
        è·å–æ–°é—»æ–‡æœ¬ (ç¿»é¡µå¼è½®æ’­ï¼Œæ¯4ç§’åˆ‡æ¢ä¸€æ¡)
        """
        if not self._news_list:
            self.get_top_stories()
        
        prefix = "ğŸ“° "
        prefix_width = 3  # emoji(2) + ç©ºæ ¼(1)
        display_width = max(10, width - prefix_width)
        
        if not self._news_list:
            return self._truncate_to_width(prefix + "æ–°é—»åŠ è½½ä¸­...", width)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢åˆ°ä¸‹ä¸€æ¡ (æ¯4ç§’åˆ‡æ¢)
        current_time = time.time()
        if not hasattr(self, '_last_flip_time'):
            self._last_flip_time = current_time
            self._flip_index = 0
        
        if current_time - self._last_flip_time >= 4.0:
            self._last_flip_time = current_time
            self._flip_index = (self._flip_index + 1) % len(self._news_list)
        
        # è·å–å½“å‰æ–°é—»
        story = self._news_list[self._flip_index]
        headline = story.get('summary') or story['title'][:50]
        source = story.get('source', '')[:8]
        
        # æ ¼å¼: ğŸ“° æ ‡é¢˜ [æ¥æº]
        text = f"{headline} [{source}]"
        
        return prefix + self._truncate_to_width(text, display_width)


# å…¨å±€å•ä¾‹
news_fetcher = NewsFetcher()
